{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 是否可用： True\n",
      "GPU 型號： NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA 是否可用：\", torch.cuda.is_available())\n",
    "print(\"GPU 型號：\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 選擇其中一個Model\n",
    "### Speech To Text, STT \n",
    "- small\n",
    "\n",
    "- medium\n",
    "\n",
    "- large-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\may4s\\lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轉錄內容： 我是員工編號EMP123 今天是2025年2月11日早上10點我今天主要負責的專案是AI研發計畫今天完成的模型訓練與部署測試但遇到的問題是GPU記憶體不足明天計畫優化LN推理速度嘗試用量化技術減少記憶體的使用\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# 加載 Whisper 並讓模型運行在 GPU\n",
    "model = whisper.load_model(\"small\").to(\"cuda\")\n",
    "\n",
    "# 轉錄音檔\n",
    "file_path = r\"C:\\Users\\User\\Dropbox\\May4s\\employee_log.m4a\"\n",
    "transcription = model.transcribe(file_path)\n",
    "\n",
    "# 輸出轉錄結果\n",
    "print(transcription[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [01:51<00:00, 13.7MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是員工編號EMP123,今天是2025年2月11日早上10點我今天主要負責的專案是AI研發計畫,今天完成了模型訓練與部署測試但遇到的問題是GPU記憶體不足,明天計畫優化LLM退理速度嘗試用量化技術減少記憶體的使用\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# 加載 Whisper 並讓模型運行在 GPU\n",
    "model = whisper.load_model(\"medium\").to(\"cuda\")\n",
    "\n",
    "# 轉錄音檔\n",
    "file_path = r\"C:\\Users\\User\\Dropbox\\May4s\\employee_log.m4a\"\n",
    "transcription = model.transcribe(file_path)\n",
    "\n",
    "# 輸出轉錄結果\n",
    "print(transcription[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.87G/2.87G [03:44<00:00, 13.8MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是員工編號EMP123今天是2025年2月11日早上10點我今天主要負責的專案是AI研發計畫今天完成了模型訓練與部署測試但遇到的問題是GPU記憶體不足明天計畫優化LLM推理速度嘗試用量化技術減少記憶體的使用\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# 加載 Whisper 並讓模型運行在 GPU\n",
    "model = whisper.load_model(\"large-v2\").to(\"cuda\")\n",
    "\n",
    "# 轉錄音檔\n",
    "file_path = r\"C:\\Users\\User\\Dropbox\\May4s\\employee_log.m4a\"\n",
    "transcription = model.transcribe(file_path)\n",
    "\n",
    "# 輸出轉錄結果\n",
    "print(transcription[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 呼叫 Ollama API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 輸出結果：  {\n",
      "      \"employee_id\": \"EMP123\",\n",
      "      \"timestamp\": \"2025-02-11T10:00:00\",\n",
      "      \"project\": \"AI研發計畫\",\n",
      "      \"summary\": \"完成了模型訓練與部署測試但遇到的問題是GPU記憶體不足,明天計畫優化LLM退理速度嘗試用量化技術減少記憶體的使用\"\n",
      "   }\n",
      "✅ 解析成功： {'employee_id': 'EMP123', 'timestamp': '2025-02-11T10:00:00', 'project': 'AI研發計畫', 'summary': '完成了模型訓練與部署測試但遇到的問題是GPU記憶體不足,明天計畫優化LLM退理速度嘗試用量化技術減少記憶體的使用'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "# 連接到 Ollama 伺服器\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "def query_ollama(prompt):\n",
    "    payload = {\n",
    "        \"model\": \"mistral:latest\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False  # 設為 False 讓回應一次返回\n",
    "    }\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    return response.json()[\"response\"]\n",
    "\n",
    "# 產生 Prompt\n",
    "prompt = f\"\"\"\n",
    "請根據以下員工日誌內容，解析出專案名稱、員工 ID、時間戳記，並輸出成 JSON 格式：\n",
    "---\n",
    "{transcription[\"text\"]}\n",
    "---\n",
    "請以 JSON 格式輸出，包含：\n",
    "- \"employee_id\"\n",
    "- \"timestamp\"\n",
    "- \"project\"\n",
    "- \"summary\"\n",
    "\"\"\"\n",
    "\n",
    "# 呼叫 Ollama\n",
    "output_text = query_ollama(prompt)\n",
    "print(\"LLM 輸出結果：\", output_text)\n",
    "\n",
    "\n",
    "# 解析 JSON，去除 LLM 可能產生的多餘文字\n",
    "match = re.search(r\"\\{.*\\}|\\[.*\\]\", output_text, re.DOTALL)\n",
    "if match:\n",
    "    json_text = match.group(0)  # 提取純 JSON\n",
    "    try:\n",
    "        parsed_output = json.loads(json_text)\n",
    "        print(\"✅ 解析成功：\", parsed_output)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"❌ JSON 解析錯誤：\", e)\n",
    "else:\n",
    "    print(\"❌ 解析失敗，請檢查 LLM 輸出\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee_id            timestamp project  \\\n",
      "0      EMP123  2025-02-11T10:00:00  AI研發計畫   \n",
      "\n",
      "                                             summary  \n",
      "0  完成了模型訓練與部署測試但遇到的問題是GPU記憶體不足,明天計畫優化LLM退理速度嘗試用量化...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 轉成 DataFrame\n",
    "df = pd.DataFrame([parsed_output])\n",
    "\n",
    "# 顯示表格\n",
    "print(df)\n",
    "\n",
    "# 存成 CSV\n",
    "df.to_csv(\"employee_log.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deepseek-r1:8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 輸出結果： <think>\n",
      "今天收到一个用户的查询，他提供了一段员工日志，让我帮他解析出专案名称、员工ID和时间戳，并以JSON格式输出。看起来用户可能是一位需要处理这些数据的管理人员或者数据分析师。\n",
      "\n",
      "首先，我要理解用户的需求。他给了一个例子，里面有员工编号EMP123，日期是2025年2月11日早上10点，项目名称是AI研發計畫，完成了一些工作，但遇到了GPU内存不足的问题，明天计划优化LLM训练速度。然后他要求生成一个包含employee_id、timestamp、project和summary的JSON。\n",
      "\n",
      "接下来，我需要分析用户提供的日志内容，提取这些信息。员工ID很明显是EMP123，时间戳是2025年2月11日早上10点，可以转换成ISO格式。项目名称就是AI研發計畫。摘要部分则需要总结当天的工作和问题，比如完成模型训练和部署测试，但遇到GPU内存不足的问题，明天计划进行优化。\n",
      "\n",
      "用户可能希望自动化处理这些日志数据，所以他们提供了一个例子，看起来是希望生成类似的JSON格式。因此，我需要确保解析正确，并且结构符合要求。\n",
      "\n",
      "最后，检查是否有其他潜在需求，比如时间戳的格式转换或者其他字段的可能性，但根据用户的要求，只需要提取这四个部分。\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"employee_id\": \"EMP123\",\n",
      "  \"timestamp\": \"2025-02-11T10:00:00Z\",\n",
      "  \"project\": \"AI研發計畫\",\n",
      "  \"summary\": \"今天主要負責AI研發計畫，完成了模型訓練與部署測試，但遇到的問題是GPU記憶體不足。明天計劃進行LLM退理速度嘗試，用量化技術減少記憶體的使用。\"\n",
      "}\n",
      "✅ 解析成功： {'employee_id': 'EMP123', 'timestamp': '2025-02-11T10:00:00Z', 'project': 'AI研發計畫', 'summary': '今天主要負責AI研發計畫，完成了模型訓練與部署測試，但遇到的問題是GPU記憶體不足。明天計劃進行LLM退理速度嘗試，用量化技術減少記憶體的使用。'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 連接到 Ollama 伺服器\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "def query_ollama(prompt):\n",
    "    payload = {\n",
    "        \"model\": \"deepseek-r1:8b\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False  # 設為 False 讓回應一次返回\n",
    "    }\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    return response.json()[\"response\"]\n",
    "\n",
    "# 產生 Prompt\n",
    "prompt = f\"\"\"\n",
    "請根據以下員工日誌內容，解析出專案名稱、員工 ID、時間戳記，並輸出成 JSON 格式：\n",
    "---\n",
    "{transcription[\"text\"]}\n",
    "---\n",
    "請以 JSON 格式輸出，包含：\n",
    "- \"employee_id\"\n",
    "- \"timestamp\"\n",
    "- \"project\"\n",
    "- \"summary\"\n",
    "\"\"\"\n",
    "\n",
    "# 呼叫 Ollama\n",
    "output_text = query_ollama(prompt)\n",
    "print(\"LLM 輸出結果：\", output_text)\n",
    "\n",
    "# 解析 JSON，去除 LLM 可能產生的多餘文字\n",
    "match = re.search(r\"\\{.*\\}|\\[.*\\]\", output_text, re.DOTALL)\n",
    "if match:\n",
    "    json_text = match.group(0)  # 提取純 JSON\n",
    "    try:\n",
    "        parsed_output = json.loads(json_text)\n",
    "        print(\"✅ 解析成功：\", parsed_output)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"❌ JSON 解析錯誤：\", e)\n",
    "else:\n",
    "    print(\"❌ 解析失敗，請檢查 LLM 輸出\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee_id             timestamp project  \\\n",
      "0      EMP123  2025-02-11T10:00:00Z  AI研發計畫   \n",
      "\n",
      "                                             summary  \n",
      "0  今天主要負責AI研發計畫，完成了模型訓練與部署測試，但遇到的問題是GPU記憶體不足。明天計劃...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 轉成 DataFrame\n",
    "df = pd.DataFrame([parsed_output])\n",
    "\n",
    "# 顯示表格\n",
    "print(df)\n",
    "\n",
    "# 存成 CSV\n",
    "df.to_csv(\"employee_log_deepseek.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phi4:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 輸出結果： 根據提供的員工日誌內容，我們可以從中解析出以下信息：\n",
      "\n",
      "1. **員工 ID**：來自“我是員工編號EMP123”。\n",
      "2. **時間戳記**：來自“今天是2025年2月11日早上10點”，所以時間戳記為2025-02-11 10:00。\n",
      "3. **專案名稱**：來自“我今天主要負責的專案是AI研發計畫”。\n",
      "4. **摘要**：包含日誌中提到的工作內容和挑戰，例如完成模型訓練與部署測試、遇到的GPU記憶體不足問題以及未來計畫。\n",
      "\n",
      "以下是以 JSON 格式輸出的結果：\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"employee_id\": \"EMP123\",\n",
      "  \"timestamp\": \"2025-02-11T10:00:00\",\n",
      "  \"project\": \"AI研發計畫\",\n",
      "  \"summary\": \"今天主要負責完成了模型訓練與部署測試，但遇到GPU記憶體不足的問題。明天計劃優化LLM退理速度並使用量化技術減少記憶體使用。\"\n",
      "}\n",
      "```\n",
      "\n",
      "此 JSON 包含了所有必要的信息，並用自然語言總結了日誌中的主要內容和計劃。\n",
      "✅ 解析成功： {'employee_id': 'EMP123', 'timestamp': '2025-02-11T10:00:00', 'project': 'AI研發計畫', 'summary': '今天主要負責完成了模型訓練與部署測試，但遇到GPU記憶體不足的問題。明天計劃優化LLM退理速度並使用量化技術減少記憶體使用。'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 連接到 Ollama 伺服器\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "def query_ollama(prompt):\n",
    "    payload = {\n",
    "        \"model\": \"phi4:latest\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False  # 設為 False 讓回應一次返回\n",
    "    }\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    return response.json()[\"response\"]\n",
    "\n",
    "# 產生 Prompt\n",
    "prompt = f\"\"\"\n",
    "請根據以下員工日誌內容，解析出專案名稱、員工 ID、時間戳記，並輸出成 JSON 格式：\n",
    "---\n",
    "{transcription[\"text\"]}\n",
    "---\n",
    "請以 JSON 格式輸出，包含：\n",
    "- \"employee_id\"\n",
    "- \"timestamp\"\n",
    "- \"project\"\n",
    "- \"summary\"\n",
    "\"\"\"\n",
    "\n",
    "# 呼叫 Ollama\n",
    "output_text = query_ollama(prompt)\n",
    "print(\"LLM 輸出結果：\", output_text)\n",
    "\n",
    "# 解析 JSON，去除 LLM 可能產生的多餘文字\n",
    "match = re.search(r\"\\{.*\\}|\\[.*\\]\", output_text, re.DOTALL)\n",
    "if match:\n",
    "    json_text = match.group(0)  # 提取純 JSON\n",
    "    try:\n",
    "        parsed_output = json.loads(json_text)\n",
    "        print(\"✅ 解析成功：\", parsed_output)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"❌ JSON 解析錯誤：\", e)\n",
    "else:\n",
    "    print(\"❌ 解析失敗，請檢查 LLM 輸出\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee_id            timestamp project  \\\n",
      "0      EMP123  2025-02-11T10:00:00  AI研發計畫   \n",
      "\n",
      "                                             summary  \n",
      "0  今天主要負責完成了模型訓練與部署測試，但遇到GPU記憶體不足的問題。明天計劃優化LLM退理速...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 轉成 DataFrame\n",
    "df = pd.DataFrame([parsed_output])\n",
    "\n",
    "# 顯示表格\n",
    "print(df)\n",
    "\n",
    "# 存成 CSV\n",
    "df.to_csv(\"employee_log_phi.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ollama chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "ollama list\n",
    "ollama run deepseek-r1:8b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "根據以下員工日誌內容，解析出專案名稱、員工 ID、時間戳記、總結，並輸出成 JSON 格式：我是員工編號EMP123今天是2025年2月11日早上10點我今天主要負責的專案是AI研發計畫今天完成了模型訓練與部署測試但遇到的問題是GPU記憶體不足明天計畫優化LLM推理速度嘗試用量化技術減少記憶體的使用\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi4:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據提供的員工日誌內容，我們可以解析出以下信息：\n",
    "- **專案名稱**：AI研發計畫\n",
    "- **員工 ID**：EMP123\n",
    "- **時間戳記**：2025年2月11日早上10點\n",
    "- **總結**：\n",
    "  - 主要負責的專案是AI研發計畫。\n",
    "  - 完成了模型訓練與部署測試。\n",
    "  - 遇到的問題是GPU記憶體不足。\n",
    "  - 明天的計畫包括優化LLM推理速度，並嘗試用量化技術來減少記憶體使用。\n",
    "\n",
    "以下是將這些信息以 JSON 格式輸出：\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"project_name\": \"AI研發計畫\",\n",
    "  \"employee_id\": \"EMP123\",\n",
    "  \"timestamp\": \"2025-02-11 10:00\",\n",
    "  \"summary\": {\n",
    "    \"responsibilities\": \"主要負責的專案是AI研發計畫。\",\n",
    "    \"accomplishments\": \"完成了模型訓練與部署測試。\",\n",
    "    \"challenges\": \"遇到的問題是GPU記憶體不足。\",\n",
    "    \"next_steps\": \"明天計畫優化LLM推理速度，嘗試用量化技術減少記憶體的使用。\"\n",
    "  }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deepseek 8b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<think>\n",
    "嗯，好的，我需要帮助用户将他们的员工日志信息转化为纯JSON格式，并添加一个摘要。首先，我要确认日志中的内容：\n",
    "\n",
    "“我是員工編號EMP123今天是2025年2月11日早上10點我今天主要負責的專案是AI研發計畫今天完成了模型訓練與部署測試但遇到的問題是GPU記憶體不足明天計畫優化LLM推理速度嘗試用量化技術減少記憶     \n",
    "體的使用”\n",
    "\n",
    "从日志中，我可以提取出以下信息：\n",
    "\n",
    "- 员工ID：EMP123\n",
    "- 日期和时间：2025年2月11日早上10點\n",
    "- 专案名称：AI 研发 计划\n",
    "\n",
    "在用户之前的查询中，我已经将这些信息转换为JSON格式。现在，用户希望添加一个摘要（summary），因此我需要根据日志内容撰写一个简短的总结。\n",
    "\n",
    "总结应该包括主要事件、遇到的问题以及下一步计划。具体来说：\n",
    "\n",
    "1. 员工完成了模型训练和部署测量。\n",
    "2. 遇到了GPU内存不足的问题。\n",
    "3. 明天计划优化LLM推理速度，尝试使用量化技术减少内存使用。\n",
    "\n",
    "基于这些信息，我可以写一个摘要，简要说明当天的工作内容、遇到的挑战以及明天的计划。\n",
    "\n",
    "接下来，我需要将这些整合成一个JSON对象，并添加summary字段。确保整个结构符合用户要求的纯JSON格式，不使用任何Markdown或其他格式。\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"employee_id\": \"EMP123\",\n",
    "  \"project_name\": \"AI 研发 计划\",\n",
    "  \"timestamp\": \"2025年2月11日早上10點\",\n",
    "  \"summary\": \"完成模型训练和部署测量，遇到GPU内存不足的问题，明天计划优化LLM推理速度并尝试使用量化技术减少内存使用。\"\n",
    "}\n",
    "```\n",
    "\n",
    "这样，我就将员工日志信息整理成了一个包含employee_id、project_name、timestamp以及summary的JSON对象。摘要部分简要总结了当天的工作内容和下一步计划，符合用户的要求。\n",
    "\n",
    "在处理这个问题时，我需要确保不遗漏任何重要信息，同时保持数据的准确性和格式的正确性。此外，还要注意JSON的语法是否正确，避免使用非标准的字符或格式。\n",
    "\n",
    "总结来说，这个过程包括：\n",
    "\n",
    "1. 理解用户的需求：提取员工ID、专案名称和时间戳，并添加一个摘要。\n",
    "2. 分析日志内容，提取所需信息。\n",
    "3. 撰写摘要，涵盖主要事件和解决问题的计划。\n",
    "4. 整合所有信息，形成正确的JSON格式。\n",
    "\n",
    "通过这些步骤，我能够准确地满足用户的要求，并提供一个结构清晰、内容完整的响应。\n",
    "</think>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"employee_id\": \"EMP123\",\n",
    "  \"project_name\": \"AI 研发 计划\",\n",
    "  \"timestamp\": \"2025年2月11日早上10點\",\n",
    "  \"summary\": \"完成模型训练和部署测量，遇到GPU内存不足的问题，明天计划优化LLM推理速度并尝试使用量化技术减少内存使用。\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "may4s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
